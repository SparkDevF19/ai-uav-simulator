{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''Authors:\n",
    "    John Quitto-Graham\n",
    "    Alejandro Torres\n",
    "    Ernest J. Quant\n",
    "    Carlos Valdes\n",
    "    Ivan Reyes\n",
    "    Orson Meyreles\n",
    "    Maria Celeste Carbonell\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import cv2\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import glob\n",
    "import matplotlib.image as mpimg \n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import Image as _Imgdis\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_training(x_train, y_train):\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train/255.0 #normalize\n",
    "    \n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    \n",
    "    #start\n",
    "    model = Sequential()\n",
    "    #insert a conv layer that accepts the image data x2\n",
    "    \n",
    "    ### READ THIS ####\n",
    "    #You had an error in the input shape, where you se (50, 50 ,1) and it should be (50, 50, 3)\n",
    "    # remember you need to be consisted with the size\n",
    "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(80,80,3)))\n",
    "    \n",
    "    #max pool layer for further processing x2\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    \n",
    "    #flatten data for full-connected layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    #regularization\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(512,activation='relu'))\n",
    "    model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    #ntrain = len(x_train)\n",
    "    #nval = len(x_test)\n",
    "    \n",
    "    \n",
    "    model.fit(x_train,y_train,epochs=10,batch_size=32)\n",
    "\n",
    "    model.save('CNN_tester.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_addr = r\"./Safe_Collection/\"\n",
    "unsafe_addr = r\"./Unsafe_Collection/\"\n",
    "test = r\"./data_set.hdf5\"\n",
    "# read the hdf5 or h5 time, use mode \"r\" for \"Only Read\"\n",
    "f = h5py.File(test, mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1410, 80, 80, 3)\n",
      "(1410,)\n"
     ]
    }
   ],
   "source": [
    "x, y = f.values()\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JohnQ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\JohnQ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "1410/1410 [==============================] - ETA: 27s - loss: 0.6972 - acc: 0.43 - ETA: 19s - loss: 8.1728 - acc: 0.46 - ETA: 17s - loss: 6.3485 - acc: 0.46 - ETA: 16s - loss: 4.9594 - acc: 0.46 - ETA: 15s - loss: 4.1128 - acc: 0.48 - ETA: 15s - loss: 3.5426 - acc: 0.48 - ETA: 14s - loss: 3.1387 - acc: 0.47 - ETA: 13s - loss: 2.8337 - acc: 0.46 - ETA: 13s - loss: 2.5985 - acc: 0.45 - ETA: 12s - loss: 2.4073 - acc: 0.46 - ETA: 12s - loss: 2.2519 - acc: 0.46 - ETA: 11s - loss: 2.1223 - acc: 0.46 - ETA: 11s - loss: 2.0122 - acc: 0.47 - ETA: 10s - loss: 1.9182 - acc: 0.46 - ETA: 10s - loss: 1.8366 - acc: 0.46 - ETA: 9s - loss: 1.7653 - acc: 0.4707 - ETA: 9s - loss: 1.7023 - acc: 0.470 - ETA: 8s - loss: 1.6464 - acc: 0.461 - ETA: 8s - loss: 1.5960 - acc: 0.470 - ETA: 8s - loss: 1.5510 - acc: 0.475 - ETA: 7s - loss: 1.5101 - acc: 0.479 - ETA: 7s - loss: 1.4738 - acc: 0.475 - ETA: 6s - loss: 1.4397 - acc: 0.481 - ETA: 6s - loss: 1.4082 - acc: 0.484 - ETA: 6s - loss: 1.3807 - acc: 0.478 - ETA: 5s - loss: 1.3543 - acc: 0.477 - ETA: 5s - loss: 1.3298 - acc: 0.481 - ETA: 5s - loss: 1.3074 - acc: 0.478 - ETA: 4s - loss: 1.2862 - acc: 0.481 - ETA: 4s - loss: 1.2665 - acc: 0.481 - ETA: 4s - loss: 1.2480 - acc: 0.476 - ETA: 3s - loss: 1.2307 - acc: 0.473 - ETA: 3s - loss: 1.2147 - acc: 0.471 - ETA: 3s - loss: 1.1995 - acc: 0.466 - ETA: 2s - loss: 1.1850 - acc: 0.468 - ETA: 2s - loss: 1.1714 - acc: 0.468 - ETA: 2s - loss: 1.1586 - acc: 0.467 - ETA: 1s - loss: 1.1463 - acc: 0.469 - ETA: 1s - loss: 1.1350 - acc: 0.466 - ETA: 1s - loss: 1.1239 - acc: 0.468 - ETA: 0s - loss: 1.1136 - acc: 0.465 - ETA: 0s - loss: 1.1035 - acc: 0.468 - ETA: 0s - loss: 1.0939 - acc: 0.470 - ETA: 0s - loss: 1.0854 - acc: 0.468 - 14s 10ms/sample - loss: 1.0848 - acc: 0.4688\n",
      "Epoch 2/10\n",
      "1410/1410 [==============================] - ETA: 11s - loss: 0.6930 - acc: 0.50 - ETA: 11s - loss: 0.6936 - acc: 0.45 - ETA: 11s - loss: 0.6924 - acc: 0.48 - ETA: 11s - loss: 0.6917 - acc: 0.53 - ETA: 11s - loss: 0.6965 - acc: 0.51 - ETA: 11s - loss: 0.6952 - acc: 0.52 - ETA: 10s - loss: 0.6956 - acc: 0.51 - ETA: 10s - loss: 0.6954 - acc: 0.50 - ETA: 10s - loss: 0.6951 - acc: 0.50 - ETA: 10s - loss: 0.6952 - acc: 0.50 - ETA: 9s - loss: 0.6946 - acc: 0.5199 - ETA: 9s - loss: 0.6937 - acc: 0.528 - ETA: 9s - loss: 0.6953 - acc: 0.519 - ETA: 9s - loss: 0.6954 - acc: 0.504 - ETA: 8s - loss: 0.6953 - acc: 0.502 - ETA: 8s - loss: 0.6953 - acc: 0.502 - ETA: 8s - loss: 0.6951 - acc: 0.509 - ETA: 8s - loss: 0.6950 - acc: 0.506 - ETA: 7s - loss: 0.6949 - acc: 0.504 - ETA: 7s - loss: 0.6944 - acc: 0.515 - ETA: 7s - loss: 0.6945 - acc: 0.513 - ETA: 6s - loss: 0.6956 - acc: 0.508 - ETA: 6s - loss: 0.6954 - acc: 0.513 - ETA: 6s - loss: 0.6950 - acc: 0.516 - ETA: 5s - loss: 0.6950 - acc: 0.517 - ETA: 5s - loss: 0.6952 - acc: 0.514 - ETA: 5s - loss: 0.6953 - acc: 0.512 - ETA: 4s - loss: 0.6953 - acc: 0.512 - ETA: 4s - loss: 0.6949 - acc: 0.516 - ETA: 4s - loss: 0.6961 - acc: 0.514 - ETA: 4s - loss: 0.6959 - acc: 0.515 - ETA: 3s - loss: 0.6960 - acc: 0.514 - ETA: 3s - loss: 0.6963 - acc: 0.509 - ETA: 3s - loss: 0.6960 - acc: 0.513 - ETA: 2s - loss: 0.6958 - acc: 0.514 - ETA: 2s - loss: 0.6959 - acc: 0.512 - ETA: 2s - loss: 0.6960 - acc: 0.510 - ETA: 1s - loss: 0.6957 - acc: 0.513 - ETA: 1s - loss: 0.6955 - acc: 0.518 - ETA: 1s - loss: 0.6957 - acc: 0.515 - ETA: 0s - loss: 0.6959 - acc: 0.514 - ETA: 0s - loss: 0.6958 - acc: 0.512 - ETA: 0s - loss: 0.6959 - acc: 0.510 - ETA: 0s - loss: 0.6957 - acc: 0.511 - 14s 10ms/sample - loss: 0.6957 - acc: 0.5106\n",
      "Epoch 3/10\n",
      "1410/1410 [==============================] - ETA: 12s - loss: 0.6870 - acc: 0.59 - ETA: 12s - loss: 0.7165 - acc: 0.45 - ETA: 12s - loss: 0.7074 - acc: 0.50 - ETA: 11s - loss: 0.7039 - acc: 0.50 - ETA: 11s - loss: 0.6985 - acc: 0.54 - ETA: 11s - loss: 0.7067 - acc: 0.52 - ETA: 11s - loss: 0.7052 - acc: 0.51 - ETA: 10s - loss: 0.7023 - acc: 0.53 - ETA: 10s - loss: 0.6974 - acc: 0.54 - ETA: 10s - loss: 0.7143 - acc: 0.52 - ETA: 9s - loss: 0.7128 - acc: 0.5256 - ETA: 9s - loss: 0.7106 - acc: 0.526 - ETA: 9s - loss: 0.7096 - acc: 0.526 - ETA: 8s - loss: 0.7085 - acc: 0.526 - ETA: 8s - loss: 0.7072 - acc: 0.527 - ETA: 8s - loss: 0.7054 - acc: 0.529 - ETA: 8s - loss: 0.7045 - acc: 0.531 - ETA: 7s - loss: 0.7037 - acc: 0.529 - ETA: 7s - loss: 0.7039 - acc: 0.524 - ETA: 7s - loss: 0.7032 - acc: 0.520 - ETA: 6s - loss: 0.7022 - acc: 0.526 - ETA: 6s - loss: 0.7000 - acc: 0.536 - ETA: 6s - loss: 0.6978 - acc: 0.540 - ETA: 6s - loss: 0.6960 - acc: 0.545 - ETA: 5s - loss: 0.6966 - acc: 0.543 - ETA: 5s - loss: 0.6959 - acc: 0.543 - ETA: 5s - loss: 0.6966 - acc: 0.535 - ETA: 4s - loss: 0.6971 - acc: 0.532 - ETA: 4s - loss: 0.6975 - acc: 0.528 - ETA: 4s - loss: 0.6974 - acc: 0.525 - ETA: 3s - loss: 0.6976 - acc: 0.521 - ETA: 3s - loss: 0.6971 - acc: 0.522 - ETA: 3s - loss: 0.6965 - acc: 0.525 - ETA: 3s - loss: 0.6961 - acc: 0.528 - ETA: 2s - loss: 0.6961 - acc: 0.528 - ETA: 2s - loss: 0.6961 - acc: 0.526 - ETA: 2s - loss: 0.6959 - acc: 0.526 - ETA: 1s - loss: 0.6960 - acc: 0.525 - ETA: 1s - loss: 0.6958 - acc: 0.524 - ETA: 1s - loss: 0.6961 - acc: 0.523 - ETA: 0s - loss: 0.6960 - acc: 0.523 - ETA: 0s - loss: 0.6956 - acc: 0.524 - ETA: 0s - loss: 0.6957 - acc: 0.523 - ETA: 0s - loss: 0.6948 - acc: 0.527 - 14s 10ms/sample - loss: 0.6950 - acc: 0.5270\n",
      "Epoch 4/10\n",
      "1410/1410 [==============================] - ETA: 13s - loss: 0.6643 - acc: 0.59 - ETA: 13s - loss: 0.8201 - acc: 0.46 - ETA: 13s - loss: 0.7735 - acc: 0.52 - ETA: 13s - loss: 0.7467 - acc: 0.54 - ETA: 12s - loss: 0.7302 - acc: 0.56 - ETA: 12s - loss: 0.7238 - acc: 0.55 - ETA: 12s - loss: 0.7160 - acc: 0.54 - ETA: 11s - loss: 0.7113 - acc: 0.53 - ETA: 11s - loss: 0.7045 - acc: 0.55 - ETA: 11s - loss: 0.6984 - acc: 0.55 - ETA: 10s - loss: 0.6983 - acc: 0.54 - ETA: 10s - loss: 0.6944 - acc: 0.54 - ETA: 10s - loss: 0.6941 - acc: 0.54 - ETA: 9s - loss: 0.6912 - acc: 0.5580 - ETA: 9s - loss: 0.6908 - acc: 0.560 - ETA: 9s - loss: 0.6900 - acc: 0.560 - ETA: 8s - loss: 0.6885 - acc: 0.562 - ETA: 8s - loss: 0.6870 - acc: 0.571 - ETA: 8s - loss: 0.6879 - acc: 0.565 - ETA: 7s - loss: 0.6986 - acc: 0.562 - ETA: 7s - loss: 0.6985 - acc: 0.562 - ETA: 7s - loss: 0.6964 - acc: 0.566 - ETA: 6s - loss: 0.6962 - acc: 0.562 - ETA: 6s - loss: 0.6955 - acc: 0.563 - ETA: 6s - loss: 0.6950 - acc: 0.558 - ETA: 5s - loss: 0.6949 - acc: 0.557 - ETA: 5s - loss: 0.6949 - acc: 0.556 - ETA: 5s - loss: 0.6948 - acc: 0.554 - ETA: 4s - loss: 0.6941 - acc: 0.559 - ETA: 4s - loss: 0.6933 - acc: 0.560 - ETA: 4s - loss: 0.6938 - acc: 0.561 - ETA: 3s - loss: 0.6942 - acc: 0.557 - ETA: 3s - loss: 0.6945 - acc: 0.554 - ETA: 3s - loss: 0.6945 - acc: 0.557 - ETA: 2s - loss: 0.6938 - acc: 0.556 - ETA: 2s - loss: 0.6939 - acc: 0.553 - ETA: 2s - loss: 0.6930 - acc: 0.557 - ETA: 1s - loss: 0.6927 - acc: 0.555 - ETA: 1s - loss: 0.6929 - acc: 0.553 - ETA: 1s - loss: 0.6932 - acc: 0.551 - ETA: 0s - loss: 0.6932 - acc: 0.551 - ETA: 0s - loss: 0.6938 - acc: 0.550 - ETA: 0s - loss: 0.6937 - acc: 0.550 - ETA: 0s - loss: 0.6943 - acc: 0.546 - 14s 10ms/sample - loss: 0.6943 - acc: 0.5475\n",
      "Epoch 5/10\n",
      "1410/1410 [==============================] - ETA: 13s - loss: 0.6851 - acc: 0.53 - ETA: 12s - loss: 0.6711 - acc: 0.57 - ETA: 13s - loss: 0.6660 - acc: 0.57 - ETA: 12s - loss: 0.6789 - acc: 0.53 - ETA: 12s - loss: 0.6738 - acc: 0.54 - ETA: 11s - loss: 0.6792 - acc: 0.52 - ETA: 11s - loss: 0.6790 - acc: 0.52 - ETA: 11s - loss: 0.6741 - acc: 0.53 - ETA: 10s - loss: 0.6712 - acc: 0.55 - ETA: 10s - loss: 0.6755 - acc: 0.55 - ETA: 10s - loss: 0.6803 - acc: 0.54 - ETA: 9s - loss: 0.6795 - acc: 0.5495 - ETA: 9s - loss: 0.6802 - acc: 0.560 - ETA: 9s - loss: 0.6774 - acc: 0.564 - ETA: 8s - loss: 0.6776 - acc: 0.554 - ETA: 8s - loss: 0.6737 - acc: 0.560 - ETA: 8s - loss: 0.6806 - acc: 0.553 - ETA: 8s - loss: 0.6777 - acc: 0.566 - ETA: 7s - loss: 0.6781 - acc: 0.569 - ETA: 7s - loss: 0.6783 - acc: 0.564 - ETA: 7s - loss: 0.6784 - acc: 0.562 - ETA: 6s - loss: 0.6787 - acc: 0.556 - ETA: 6s - loss: 0.6805 - acc: 0.553 - ETA: 6s - loss: 0.6806 - acc: 0.552 - ETA: 5s - loss: 0.6807 - acc: 0.550 - ETA: 5s - loss: 0.6801 - acc: 0.554 - ETA: 5s - loss: 0.6794 - acc: 0.555 - ETA: 4s - loss: 0.6785 - acc: 0.558 - ETA: 4s - loss: 0.6785 - acc: 0.558 - ETA: 4s - loss: 0.6793 - acc: 0.558 - ETA: 4s - loss: 0.6785 - acc: 0.559 - ETA: 3s - loss: 0.6785 - acc: 0.561 - ETA: 3s - loss: 0.6788 - acc: 0.562 - ETA: 3s - loss: 0.6776 - acc: 0.564 - ETA: 2s - loss: 0.6789 - acc: 0.562 - ETA: 2s - loss: 0.6821 - acc: 0.561 - ETA: 2s - loss: 0.6818 - acc: 0.560 - ETA: 1s - loss: 0.6812 - acc: 0.565 - ETA: 1s - loss: 0.6809 - acc: 0.563 - ETA: 1s - loss: 0.6797 - acc: 0.566 - ETA: 0s - loss: 0.6798 - acc: 0.565 - ETA: 0s - loss: 0.6801 - acc: 0.566 - ETA: 0s - loss: 0.6817 - acc: 0.561 - ETA: 0s - loss: 0.6808 - acc: 0.566 - 14s 10ms/sample - loss: 0.6807 - acc: 0.5660\n",
      "Epoch 6/10\n",
      "1410/1410 [==============================] - ETA: 12s - loss: 0.6099 - acc: 0.62 - ETA: 12s - loss: 0.6251 - acc: 0.65 - ETA: 12s - loss: 0.6278 - acc: 0.66 - ETA: 12s - loss: 0.6294 - acc: 0.65 - ETA: 12s - loss: 0.6472 - acc: 0.63 - ETA: 11s - loss: 0.6481 - acc: 0.63 - ETA: 11s - loss: 0.6579 - acc: 0.62 - ETA: 11s - loss: 0.6517 - acc: 0.63 - ETA: 10s - loss: 0.6540 - acc: 0.63 - ETA: 10s - loss: 0.6548 - acc: 0.63 - ETA: 10s - loss: 0.6533 - acc: 0.63 - ETA: 10s - loss: 0.6581 - acc: 0.61 - ETA: 9s - loss: 0.6644 - acc: 0.6034 - ETA: 9s - loss: 0.6684 - acc: 0.593 - ETA: 9s - loss: 0.6643 - acc: 0.602 - ETA: 8s - loss: 0.6687 - acc: 0.597 - ETA: 8s - loss: 0.6682 - acc: 0.597 - ETA: 8s - loss: 0.6659 - acc: 0.595 - ETA: 7s - loss: 0.6662 - acc: 0.595 - ETA: 7s - loss: 0.6681 - acc: 0.592 - ETA: 7s - loss: 0.6668 - acc: 0.598 - ETA: 6s - loss: 0.6660 - acc: 0.600 - ETA: 6s - loss: 0.6653 - acc: 0.599 - ETA: 6s - loss: 0.6628 - acc: 0.602 - ETA: 5s - loss: 0.6643 - acc: 0.603 - ETA: 5s - loss: 0.6643 - acc: 0.601 - ETA: 5s - loss: 0.6661 - acc: 0.592 - ETA: 4s - loss: 0.6651 - acc: 0.593 - ETA: 4s - loss: 0.6674 - acc: 0.588 - ETA: 4s - loss: 0.6669 - acc: 0.585 - ETA: 4s - loss: 0.6679 - acc: 0.583 - ETA: 3s - loss: 0.6679 - acc: 0.584 - ETA: 3s - loss: 0.6681 - acc: 0.581 - ETA: 3s - loss: 0.6666 - acc: 0.582 - ETA: 2s - loss: 0.6672 - acc: 0.583 - ETA: 2s - loss: 0.6673 - acc: 0.582 - ETA: 2s - loss: 0.6670 - acc: 0.582 - ETA: 1s - loss: 0.6677 - acc: 0.583 - ETA: 1s - loss: 0.6672 - acc: 0.584 - ETA: 1s - loss: 0.6663 - acc: 0.585 - ETA: 0s - loss: 0.6651 - acc: 0.589 - ETA: 0s - loss: 0.6625 - acc: 0.594 - ETA: 0s - loss: 0.6605 - acc: 0.598 - ETA: 0s - loss: 0.6640 - acc: 0.592 - 14s 10ms/sample - loss: 0.6639 - acc: 0.5922\n",
      "Epoch 7/10\n",
      "1410/1410 [==============================] - ETA: 12s - loss: 0.5744 - acc: 0.78 - ETA: 12s - loss: 0.6330 - acc: 0.64 - ETA: 12s - loss: 0.6272 - acc: 0.64 - ETA: 12s - loss: 0.6284 - acc: 0.65 - ETA: 11s - loss: 0.6193 - acc: 0.65 - ETA: 11s - loss: 0.6086 - acc: 0.67 - ETA: 11s - loss: 0.6024 - acc: 0.67 - ETA: 11s - loss: 0.6111 - acc: 0.67 - ETA: 11s - loss: 0.6001 - acc: 0.68 - ETA: 10s - loss: 0.6002 - acc: 0.69 - ETA: 10s - loss: 0.6137 - acc: 0.68 - ETA: 10s - loss: 0.6093 - acc: 0.68 - ETA: 9s - loss: 0.6120 - acc: 0.6851 - ETA: 9s - loss: 0.6258 - acc: 0.674 - ETA: 9s - loss: 0.6277 - acc: 0.670 - ETA: 9s - loss: 0.6284 - acc: 0.666 - ETA: 8s - loss: 0.6296 - acc: 0.665 - ETA: 8s - loss: 0.6329 - acc: 0.661 - ETA: 8s - loss: 0.6352 - acc: 0.653 - ETA: 7s - loss: 0.6373 - acc: 0.646 - ETA: 7s - loss: 0.6372 - acc: 0.642 - ETA: 7s - loss: 0.6381 - acc: 0.642 - ETA: 6s - loss: 0.6393 - acc: 0.637 - ETA: 6s - loss: 0.6389 - acc: 0.639 - ETA: 6s - loss: 0.6409 - acc: 0.632 - ETA: 5s - loss: 0.6455 - acc: 0.623 - ETA: 5s - loss: 0.6449 - acc: 0.626 - ETA: 5s - loss: 0.6423 - acc: 0.631 - ETA: 4s - loss: 0.6453 - acc: 0.629 - ETA: 4s - loss: 0.6465 - acc: 0.625 - ETA: 4s - loss: 0.6454 - acc: 0.627 - ETA: 3s - loss: 0.6458 - acc: 0.623 - ETA: 3s - loss: 0.6454 - acc: 0.623 - ETA: 3s - loss: 0.6425 - acc: 0.624 - ETA: 2s - loss: 0.6405 - acc: 0.625 - ETA: 2s - loss: 0.6407 - acc: 0.625 - ETA: 2s - loss: 0.6413 - acc: 0.625 - ETA: 1s - loss: 0.6410 - acc: 0.625 - ETA: 1s - loss: 0.6380 - acc: 0.628 - ETA: 1s - loss: 0.6404 - acc: 0.626 - ETA: 0s - loss: 0.6408 - acc: 0.627 - ETA: 0s - loss: 0.6416 - acc: 0.625 - ETA: 0s - loss: 0.6423 - acc: 0.624 - ETA: 0s - loss: 0.6412 - acc: 0.625 - 14s 10ms/sample - loss: 0.6411 - acc: 0.6262\n",
      "Epoch 8/10\n",
      " 896/1410 [==================>...........] - ETA: 14s - loss: 0.5854 - acc: 0.68 - ETA: 15s - loss: 0.5572 - acc: 0.76 - ETA: 15s - loss: 0.5771 - acc: 0.71 - ETA: 14s - loss: 0.5810 - acc: 0.70 - ETA: 13s - loss: 0.5882 - acc: 0.68 - ETA: 12s - loss: 0.5810 - acc: 0.69 - ETA: 12s - loss: 0.5941 - acc: 0.67 - ETA: 12s - loss: 0.6091 - acc: 0.66 - ETA: 11s - loss: 0.6086 - acc: 0.66 - ETA: 11s - loss: 0.6141 - acc: 0.65 - ETA: 10s - loss: 0.6163 - acc: 0.64 - ETA: 10s - loss: 0.6139 - acc: 0.65 - ETA: 10s - loss: 0.6146 - acc: 0.65 - ETA: 9s - loss: 0.6099 - acc: 0.6652 - ETA: 9s - loss: 0.6085 - acc: 0.662 - ETA: 9s - loss: 0.6069 - acc: 0.664 - ETA: 8s - loss: 0.6066 - acc: 0.661 - ETA: 8s - loss: 0.6048 - acc: 0.661 - ETA: 8s - loss: 0.6052 - acc: 0.657 - ETA: 7s - loss: 0.6081 - acc: 0.659 - ETA: 7s - loss: 0.6095 - acc: 0.660 - ETA: 7s - loss: 0.6100 - acc: 0.663 - ETA: 6s - loss: 0.6120 - acc: 0.663 - ETA: 6s - loss: 0.6126 - acc: 0.665 - ETA: 6s - loss: 0.6142 - acc: 0.662 - ETA: 5s - loss: 0.6135 - acc: 0.662 - ETA: 5s - loss: 0.6127 - acc: 0.662 - ETA: 5s - loss: 0.6156 - acc: 0.6596"
     ]
    }
   ],
   "source": [
    "CNN_training(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
